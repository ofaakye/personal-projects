{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:23.163172Z",
     "start_time": "2025-02-04T19:43:23.160739Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1806b8c6b59691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:23.204172Z",
     "start_time": "2025-02-04T19:43:23.202222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting logging level for pypdf\n",
    "import logging\n",
    "\n",
    "\n",
    "logger = logging.getLogger(\"pypdf\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2dc1c9c79481d66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:23.801106Z",
     "start_time": "2025-02-04T19:43:23.207832Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/tax_appeal/a1compsales.pdf\",\n",
    "                 \"./data/tax_appeal/A-Guide-to-Tax-Appeal-Hearings.pdf\",\n",
    "                 \"./data/tax_appeal/FAQs.Summary-Hearing-update.pdf\",\n",
    "                 \"./data/tax_appeal/Petition-of-Appeal.pdf\",\n",
    "                 \"./data/tax_appeal/What-to-expect-at-Hearing.3.29.2022.pdf\",\n",
    "                \"./data/tax_appeal/Instructions.pdf\",\n",
    "                 ]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57575d12a830d36e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:23.807986Z",
     "start_time": "2025-02-04T19:43:23.805703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of whole document: <class 'list'>, \n",
      "\n",
      "Length of document: 26 \n",
      "\n",
      "Type of first document: <class 'llama_index.core.schema.Document'> \n",
      "\n",
      "Contents of last document: Doc ID: 8178b696-b70f-4619-908e-07930d35b7af\n",
      "Text: the date of the service of the judgment (date of mailing). If\n",
      "the assessed value of the property subject to the appeal exceeds\n",
      "$1,000,000, a taxpayer or taxing district may file a petition of\n",
      "appeal with the county board of taxation or a complaint with the Tax\n",
      "Court directly in accordance with amendatory legislation and Tax Court\n",
      "rules. The Tax ...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Type of whole document: {type(documents)}, \\n\")\n",
    "print(f\"Length of document: {len(documents)} \\n\")\n",
    "print(f\"Type of first document: {type(documents[0])} \\n\")\n",
    "print(f\"Contents of last document: {documents[25]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ccc882907c508d",
   "metadata": {},
   "source": [
    "## Basic RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77158c07ac031a2",
   "metadata": {},
   "source": [
    "#### Data Ingestion Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb0efc0738c065d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:23.818971Z",
     "start_time": "2025-02-04T19:43:23.817155Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create single document\n",
    "from llama_index.core import Document\n",
    "\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6a2c124d41533c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:30.389671Z",
     "start_time": "2025-02-04T19:43:23.823495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create chucks, embeddings and index\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "Settings.llm  = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "index = VectorStoreIndex.from_documents([document],\n",
    "                                        llm=Settings.llm,\n",
    "                                        embed_model=Settings.embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "605e92fdeb218442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:30.397505Z",
     "start_time": "2025-02-04T19:43:30.394655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stores_text': FieldInfo(annotation=bool, required=False, default=False),\n",
       " 'is_embedding_query': FieldInfo(annotation=bool, required=False, default=True),\n",
       " 'data': FieldInfo(annotation=SimpleVectorStoreData, required=False, default_factory=SimpleVectorStoreData)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the fields in the does the vector store\n",
    "index.vector_store.model_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc4f1009e4bcfb6",
   "metadata": {},
   "source": [
    "#### Retrieval and Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd312efe6bdfce8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:30.408561Z",
     "start_time": "2025-02-04T19:43:30.406980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create query engine\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c761fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are steps to take to appeal property taxes?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ff4d6718867de3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:33.050542Z",
     "start_time": "2025-02-04T19:43:30.417313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the comparable sales should include the subject property even if the sale was more than a year ago. The sale of the subject property can still be considered as a comparable sale as long as it meets the criteria of being similar in characteristics to the neighboring properties sold.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Should the comparable sales include the subject property even though the sale was more than a year ago?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76bc44f44d2b3c",
   "metadata": {},
   "source": [
    "#### For a simple example this result could suffice but to put this model in production we need to validate the response from the LLM based on the context provided.\n",
    "#### There several ways to evaluation the accuracy of a RAG application. TruLens package is one way which offers a scalable automated way to assessing  accuracy using the RAG Triad: Context Relevance, Response Relevance and Groundedness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34de58e2680ca6f",
   "metadata": {},
   "source": [
    "## Evaluation RAG Application using TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3341eaac7587e76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:33.058589Z",
     "start_time": "2025-02-04T19:43:33.055618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are steps to take to appeal property taxes?\n",
      "How long does the tax appeal process take?\n",
      "Generally is the tax appeal process challenging?\n",
      "Where can one find comparable sales to build a strong appeals case?\n",
      "Can a tax appeal be denied for no reason?\n",
      "Can a tax appeal lead to an increase in property texes?\n",
      "What is the likelihood that a tax appeal is accepted?\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation question\n",
    "evaluation_questions = []\n",
    "with open('./data/eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        evaluation_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17dd9fb7725dfdf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:33.276765Z",
     "start_time": "2025-02-04T19:43:33.066022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2645e0534a3eb972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:33.352079Z",
     "start_time": "2025-02-04T19:43:33.282674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Groundedness, input source will be set to __record__.calls[-1].rets.source_nodes[:].node.text.collect() .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input context will be set to __record__.calls[-1].rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "# Initialize provider class\n",
    "provider = TrulensOpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "\n",
    "context = TruLlama.select_context(query_engine)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(context.collect())  # collect context chunks into a list\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons, name=\"Answer Relevance\"\n",
    ").on_input_output()\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dd0f507655ff3a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:33.658379Z",
     "start_time": "2025-02-04T19:43:33.357817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.base.embeddings.base.BaseEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.callbacks.base.CallbackManager'> because of class\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
      "instrumenting <class 'tuple'> for base <class 'tuple'>\n",
      "instrumenting <class 'tuple'> for base <class 'object'>\n",
      "instrumenting <class 'pydantic.fields.FieldInfo'> for base <class 'pydantic.fields.FieldInfo'>\n",
      "instrumenting <class 'pydantic.fields.FieldInfo'> for base <class 'pydantic._internal._repr.Representation'>\n",
      "instrumenting <class 'pydantic.fields.FieldInfo'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.types.BasePydanticVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> because of class\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.base.BaseIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> because of class\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'llama_index.core.graph_stores.types.GraphStore'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Protocol'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.MetadataAwareTextSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.TextSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.NodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> because of class\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.keyval_docstore.KVDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.types.BaseDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.data_structs.data_structs.IndexDict'> because of class\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'llama_index.core.data_structs.data_structs.IndexStruct'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'llama_index.core.storage.docstore.types.RefDocInfo'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.storage.storage_context.StorageContext'> because of class\n",
      "instrumenting <class 'llama_index.core.storage.storage_context.StorageContext'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.llms.openai.base.OpenAI'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.function_calling.FunctionCallingLLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.llm.LLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.llms.base.BaseLLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'llama_index.core.base.llms.types.LLMMetadata'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.indices.prompt_helper.PromptHelper'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.refine.Refine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.base.BaseSynthesizer'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> because of class\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> because of class\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.base_query_engine.BaseQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'object'>\n"
     ]
    }
   ],
   "source": [
    "tru_query_engine_recorder = TruLlama(\n",
    "    query_engine,\n",
    "    app_name = \"TaxAppeal\",\n",
    "    app_version=\"base\",\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad54431e546fe883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:43.390126Z",
     "start_time": "2025-02-04T19:43:33.664129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling <function BaseQueryEngine.query at 0x11f855c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, 'What are steps to take to appeal property taxes?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x128b88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, QueryBundle(query_str='What are steps to take to appeal property taxes?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x11faf1580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='What are steps to take to appeal property taxes?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x128007e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='What are steps to take to appeal property taxes?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x11fcd7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function Refine.get_response at 0x11fe50e00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function BaseQueryEngine.query at 0x11f855c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, 'How long does the tax appeal process take?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x128b88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, QueryBundle(query_str='How long does the tax appeal process take?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x11faf1580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='How long does the tax appeal process take?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x128007e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='How long does the tax appeal process take?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x11fcd7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function Refine.get_response at 0x11fe50e00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function BaseQueryEngine.query at 0x11f855c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, 'Generally is the tax appeal process challenging?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x128b88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, QueryBundle(query_str='Generally is the tax appeal process challenging?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x11faf1580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='Generally is the tax appeal process challenging?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x128007e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='Generally is the tax appeal process challenging?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x11fcd7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function Refine.get_response at 0x11fe50e00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function BaseQueryEngine.query at 0x11f855c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, 'Where can one find comparable sales to build a strong appeals case?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x128b88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, QueryBundle(query_str='Where can one find comparable sales to build a strong appeals case?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x11faf1580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='Where can one find comparable sales to build a strong appeals case?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x128007e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='Where can one find comparable sales to build a strong appeals case?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x11fcd7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function Refine.get_response at 0x11fe50e00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function BaseQueryEngine.query at 0x11f855c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, 'Can a tax appeal be denied for no reason?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x128b88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, QueryBundle(query_str='Can a tax appeal be denied for no reason?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x11faf1580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='Can a tax appeal be denied for no reason?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x128007e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='Can a tax appeal be denied for no reason?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x11fcd7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function Refine.get_response at 0x11fe50e00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function BaseQueryEngine.query at 0x11f855c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, 'Can a tax appeal lead to an increase in property texes?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x128b88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, QueryBundle(query_str='Can a tax appeal lead to an increase in property texes?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x11faf1580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='Can a tax appeal lead to an increase in property texes?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x128007e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='Can a tax appeal lead to an increase in property texes?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x11fcd7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function Refine.get_response at 0x11fe50e00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function BaseQueryEngine.query at 0x11f855c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, 'What is the likelihood that a tax appeal is accepted?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x128b88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x1691cfa90>, QueryBundle(query_str='What is the likelihood that a tax appeal is accepted?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x11faf1580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='What is the likelihood that a tax appeal is accepted?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x128007e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x33fc2f710>, QueryBundle(query_str='What is the likelihood that a tax appeal is accepted?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x11fcd7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n",
      "calling <function Refine.get_response at 0x11fe50e00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x16934cf50>,)\n"
     ]
    }
   ],
   "source": [
    "# Evaluation each question and record results\n",
    "with tru_query_engine_recorder as recording:\n",
    "    for question in evaluation_questions:\n",
    "        response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca6f654d3fdc989c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T19:43:43.891779Z",
     "start_time": "2025-02-04T19:43:43.395576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ab23ae0d9c4a268dedee11baf8b80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.1.20:59041 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae30ffc45f06d2b3",
   "metadata": {},
   "source": [
    "![Local Image](images/trulens_output.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
