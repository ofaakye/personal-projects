{
 "cells": [
  {
   "cell_type": "code",
   "id": "166d2f1bde15f756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:26.723919Z",
     "start_time": "2025-01-31T16:22:21.922189Z"
    }
   },
   "source": [
    "# Import packages\n",
    "import openai\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from llama_index.core import Document\n",
    "\n",
    "from trulens.core import Feedback, Select\n",
    "from trulens.apps.llamaindex import TruLlama\n",
    "from trulens.providers.openai import OpenAI as TrulensOpenAI"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:26.729898Z",
     "start_time": "2025-01-31T16:22:26.727451Z"
    }
   },
   "source": [
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "9c1806b8c6b59691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:26.771980Z",
     "start_time": "2025-01-31T16:22:26.770372Z"
    }
   },
   "source": [
    "# Setting logging level for pypdf\n",
    "logger = logging.getLogger(\"pypdf\")\n",
    "logger.setLevel(logging.ERROR)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "e2dc1c9c79481d66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:27.359786Z",
     "start_time": "2025-01-31T16:22:26.778820Z"
    }
   },
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/tax_appeal/a1compsales.pdf\",\n",
    "                 \"./data/tax_appeal/A-Guide-to-Tax-Appeal-Hearings.pdf\",\n",
    "                 \"./data/tax_appeal/FAQs.Summary-Hearing-update.pdf\",\n",
    "                 \"./data/tax_appeal/Petition-of-Appeal.pdf\",\n",
    "                 \"./data/tax_appeal/What-to-expect-at-Hearing.3.29.2022.pdf\",\n",
    "                \"./data/tax_appeal/Instructions.pdf\",\n",
    "                 ]\n",
    ").load_data()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "57575d12a830d36e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:27.423115Z",
     "start_time": "2025-01-31T16:22:27.420662Z"
    }
   },
   "source": [
    "print(f\"Type of whole document: {type(documents)}, \\n\")\n",
    "print(f\"Length of document: {len(documents)} \\n\")\n",
    "print(f\"Type of first document: {type(documents[0])} \\n\")\n",
    "print(f\"Contents of last document: {documents[25]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of whole document: <class 'list'>, \n",
      "\n",
      "Length of document: 26 \n",
      "\n",
      "Type of first document: <class 'llama_index.core.schema.Document'> \n",
      "\n",
      "Contents of last document: Doc ID: c154df07-914f-4b62-9d65-5ac760525411\n",
      "Text: the date of the service of the judgment (date of mailing). If\n",
      "the assessed value of the property subject to the appeal exceeds\n",
      "$1,000,000, a taxpayer or taxing district may file a petition of\n",
      "appeal with the county board of taxation or a complaint with the Tax\n",
      "Court directly in accordance with amendatory legislation and Tax Court\n",
      "rules. The Tax ...\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "89ccc882907c508d",
   "metadata": {},
   "source": [
    "## Basic RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77158c07ac031a2",
   "metadata": {},
   "source": [
    "#### Data Ingestion Phase"
   ]
  },
  {
   "cell_type": "code",
   "id": "bbb0efc0738c065d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:27.439214Z",
     "start_time": "2025-01-31T16:22:27.437491Z"
    }
   },
   "source": [
    "# Create single document\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "f6a2c124d41533c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:36.512293Z",
     "start_time": "2025-01-31T16:22:27.444701Z"
    }
   },
   "source": [
    "# Create chucks, embeddings and index\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "Settings.llm  = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "index = VectorStoreIndex.from_documents([document],\n",
    "                                        llm=Settings.llm,\n",
    "                                        embed_model=Settings.embed_model)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "605e92fdeb218442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:36.520806Z",
     "start_time": "2025-01-31T16:22:36.517716Z"
    }
   },
   "source": [
    "# what are the fields in the does the vector store\n",
    "index.vector_store.model_fields"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stores_text': FieldInfo(annotation=bool, required=False, default=False),\n",
       " 'is_embedding_query': FieldInfo(annotation=bool, required=False, default=True),\n",
       " 'data': FieldInfo(annotation=SimpleVectorStoreData, required=False, default_factory=SimpleVectorStoreData)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "fdc4f1009e4bcfb6",
   "metadata": {},
   "source": [
    "#### Retrieval and Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd312efe6bdfce8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:36.527263Z",
     "start_time": "2025-01-31T16:22:36.525576Z"
    }
   },
   "source": [
    "# Create query engine\n",
    "query_engine = index.as_query_engine()"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "8ff4d6718867de3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:39.052358Z",
     "start_time": "2025-01-31T16:22:36.536057Z"
    }
   },
   "source": [
    "response = query_engine.query(\n",
    "    \"What are steps to take to appeal property taxes?\"\n",
    ")\n",
    "print(str(response))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps to take to appeal property taxes include preparing evidence and papers, providing comparable sales with explanations, submitting photographs of the property and comparable sales, attending the hearing or requesting a reschedule with valid reasons, and ensuring all evidence is submitted at least 7 days before the hearing date. It is important to be concise, focused, and prepared to discuss major points during the hearing. Additionally, following the guidelines for filing the appeal, including submitting required forms and fees, is crucial in the process.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### For a simple example this result could suffice but to put this model in production we need to validate the response from the LLM based on the context provided.\n",
    "#### There several ways to evaluation the accuracy of a RAG application. TruLens package is one way which offers a scalable automated way to assessing  accuracy using the RAG Triad: Context Relevance, Response Relevance and Groundedness"
   ],
   "id": "5d76bc44f44d2b3c"
  },
  {
   "cell_type": "markdown",
   "id": "d34de58e2680ca6f",
   "metadata": {},
   "source": "## Evaluation RAG Application using TruLens"
  },
  {
   "cell_type": "code",
   "id": "c3341eaac7587e76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:39.065464Z",
     "start_time": "2025-01-31T16:22:39.062095Z"
    }
   },
   "source": [
    "# Load evaluation question\n",
    "evaluation_questions = []\n",
    "with open('./data/eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        evaluation_questions.append(item)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are steps to take to appeal property taxes?\n",
      "How long does the tax appeal process take?\n",
      "Generally is the tax appeal process challenging?\n",
      "Where can one find comparable sales to build a string appeals case?\n",
      "Can a tax appeal be denied for no reason?\n",
      "Can a tax appeal lead to an increase in property texes?\n",
      "What is the likelihood that a tax appeal is accepted?\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "17dd9fb7725dfdf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:39.295813Z",
     "start_time": "2025-01-31T16:22:39.079237Z"
    }
   },
   "source": [
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð¦ Initialized with db url sqlite:///default.sqlite .\n",
      "ð Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "2645e0534a3eb972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:39.380286Z",
     "start_time": "2025-01-31T16:22:39.301594Z"
    }
   },
   "source": [
    "# Initialize provider class\n",
    "provider = TrulensOpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "\n",
    "context = TruLlama.select_context(query_engine)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(context.collect())  # collect context chunks into a list\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons, name=\"Answer Relevance\"\n",
    ").on_input_output()\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â In Groundedness, input source will be set to __record__.calls[-1].rets.source_nodes[:].node.text.collect() .\n",
      "â In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "â In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "â In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "â In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "â In Context Relevance, input context will be set to __record__.calls[-1].rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "2dd0f507655ff3a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:39.713869Z",
     "start_time": "2025-01-31T16:22:39.386279Z"
    }
   },
   "source": [
    "tru_query_engine_recorder = TruLlama(\n",
    "    query_engine,\n",
    "    app_name = \"TaxAppeal\",\n",
    "    app_version=\"base\",\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.base.embeddings.base.BaseEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.callbacks.base.CallbackManager'> because of class\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
      "instrumenting <class 'tuple'> for base <class 'tuple'>\n",
      "instrumenting <class 'tuple'> for base <class 'object'>\n",
      "instrumenting <class 'pydantic.fields.FieldInfo'> for base <class 'pydantic.fields.FieldInfo'>\n",
      "instrumenting <class 'pydantic.fields.FieldInfo'> for base <class 'pydantic._internal._repr.Representation'>\n",
      "instrumenting <class 'pydantic.fields.FieldInfo'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.types.BasePydanticVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> because of class\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.base.BaseIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> because of class\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'llama_index.core.graph_stores.types.GraphStore'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Protocol'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.MetadataAwareTextSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.TextSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.NodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> because of class\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.keyval_docstore.KVDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.types.BaseDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.data_structs.data_structs.IndexDict'> because of class\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'llama_index.core.data_structs.data_structs.IndexStruct'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'llama_index.core.storage.docstore.types.RefDocInfo'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.storage.storage_context.StorageContext'> because of class\n",
      "instrumenting <class 'llama_index.core.storage.storage_context.StorageContext'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.llms.openai.base.OpenAI'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.function_calling.FunctionCallingLLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.llm.LLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.llms.base.BaseLLM'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'llama_index.core.base.llms.types.LLMMetadata'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.indices.prompt_helper.PromptHelper'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.refine.Refine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.base.BaseSynthesizer'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> because of class\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "skipping base <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> because of class\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.base_query_engine.BaseQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'object'>\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "ad54431e546fe883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:51.719403Z",
     "start_time": "2025-01-31T16:22:39.719753Z"
    }
   },
   "source": [
    "# Evaluation each question and record results\n",
    "with tru_query_engine_recorder as recording:\n",
    "    for question in evaluation_questions:\n",
    "        response = query_engine.query(question)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling <function BaseQueryEngine.query at 0x141a55c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, 'What are steps to take to appeal property taxes?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x142c88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, QueryBundle(query_str='What are steps to take to appeal property taxes?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x141cf5580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='What are steps to take to appeal property taxes?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x142407e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='What are steps to take to appeal property taxes?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x1420d7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n",
      "calling <function Refine.get_response at 0x14214ce00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n",
      "calling <function BaseQueryEngine.query at 0x141a55c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, 'How long does the tax appeal process take?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x142c88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, QueryBundle(query_str='How long does the tax appeal process take?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x141cf5580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='How long does the tax appeal process take?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x142407e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='How long does the tax appeal process take?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x1420d7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n",
      "calling <function Refine.get_response at 0x14214ce00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n",
      "calling <function BaseQueryEngine.query at 0x141a55c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, 'Generally is the tax appeal process challenging?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x142c88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, QueryBundle(query_str='Generally is the tax appeal process challenging?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x141cf5580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='Generally is the tax appeal process challenging?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x142407e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='Generally is the tax appeal process challenging?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x1420d7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n",
      "calling <function Refine.get_response at 0x14214ce00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ofaakye/.pyenv/versions/llms/lib/python3.11/site-packages/trulens/feedback/llm_provider.py:1521: UserWarning: Failed to process and remove trivial statements. Proceeding with all statements.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling <function BaseQueryEngine.query at 0x141a55c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, 'Where can one find comparable sales to build a string appeals case?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x142c88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, QueryBundle(query_str='Where can one find comparable sales to build a string appeals case?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x141cf5580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='Where can one find comparable sales to build a string appeals case?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x142407e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='Where can one find comparable sales to build a string appeals case?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x1420d7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n",
      "calling <function Refine.get_response at 0x14214ce00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n",
      "calling <function BaseQueryEngine.query at 0x141a55c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, 'Can a tax appeal be denied for no reason?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x142c88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, QueryBundle(query_str='Can a tax appeal be denied for no reason?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x141cf5580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='Can a tax appeal be denied for no reason?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x142407e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='Can a tax appeal be denied for no reason?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x1420d7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n",
      "calling <function Refine.get_response at 0x14214ce00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n",
      "calling <function BaseQueryEngine.query at 0x141a55c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, 'Can a tax appeal lead to an increase in property texes?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x142c88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, QueryBundle(query_str='Can a tax appeal lead to an increase in property texes?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x141cf5580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='Can a tax appeal lead to an increase in property texes?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x142407e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='Can a tax appeal lead to an increase in property texes?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x1420d7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n",
      "calling <function Refine.get_response at 0x14214ce00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n",
      "calling <function BaseQueryEngine.query at 0x141a55c60> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, 'What is the likelihood that a tax appeal is accepted?')\n",
      "calling <function RetrieverQueryEngine.retrieve at 0x142c88540> with (<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x141a1e210>, QueryBundle(query_str='What is the likelihood that a tax appeal is accepted?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function BaseRetriever.retrieve at 0x141cf5580> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='What is the likelihood that a tax appeal is accepted?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function VectorIndexRetriever._retrieve at 0x142407e20> with (<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever object at 0x153566b10>, QueryBundle(query_str='What is the likelihood that a tax appeal is accepted?', image_path=None, custom_embedding_strs=None, embedding=None))\n",
      "calling <function CompactAndRefine.get_response at 0x1420d7600> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n",
      "calling <function Refine.get_response at 0x14214ce00> with (<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine object at 0x144bbc150>,)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "ca6f654d3fdc989c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:22:52.280292Z",
     "start_time": "2025-01-31T16:22:51.735991Z"
    }
   },
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b536d4220d0c4083af6f2f743b56d3cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://10.201.232.41:55258 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![Local Image](images/trulens_output.png)",
   "id": "ae30ffc45f06d2b3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
